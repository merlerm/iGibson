{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90c47d0-366a-4683-adc1-5d6e9ce47850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _   _____  _  _\n",
      "(_) / ____|(_)| |\n",
      " _ | |  __  _ | |__   ___   ___   _ __\n",
      "| || | |_ || || '_ \\ / __| / _ \\ | '_ \\\n",
      "| || |__| || || |_) |\\__ \\| (_) || | | |\n",
      "|_| \\_____||_||_.__/ |___/ \\___/ |_| |_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import igibson\n",
    "from igibson.action_primitives.action_primitive_set_base import ActionPrimitiveError\n",
    "from igibson.action_primitives.starter_semantic_action_primitives import StarterSemanticActionPrimitives\n",
    "from igibson.objects.articulated_object import URDFObject\n",
    "from igibson.robots.behavior_robot import BehaviorRobot\n",
    "from igibson.robots.fetch import Fetch\n",
    "from igibson.scenes.igibson_indoor_scene import InteractiveIndoorScene\n",
    "from igibson.simulator import Simulator\n",
    "from igibson.utils.assets_utils import get_ig_avg_category_specs, get_ig_model_path\n",
    "from igibson.utils.utils import parse_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdeef5df-4326-46f6-b765-40455956172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_controller(ctrl_gen, robot, s):\n",
    "    for action in ctrl_gen:\n",
    "        robot.apply_action(action)\n",
    "        s.step()\n",
    "\n",
    "\n",
    "def go_to_table(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Go to the table object in the scene.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            table = s.scene.objects_by_category[\"coffee_table\"][0]\n",
    "            print(\"Trying to NAVIGATE_TO table.\")\n",
    "            execute_controller(controller._navigate_to_obj(table), robot, s)\n",
    "            print(\"NAVIGATE_TO table succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to navigate to table failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "def go_to_table_simpler(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Go to the table object in the scene.\"\"\"\n",
    "    table = s.scene.objects_by_category[\"coffee_table\"][0]\n",
    "    print(\"Trying to NAVIGATE_TO table.\")\n",
    "    execute_controller(controller._navigate_to_obj(table), robot, s)\n",
    "    print(\"NAVIGATE_TO table succeeded!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7699a2e2-6b17-4728-babe-0b3883374a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:igibson.render.mesh_renderer.get_available_devices:Device 0 is available for rendering\n",
      "INFO:igibson.render.mesh_renderer.get_available_devices:Command '['/home/nicola/python_projects/iGibson/igibson/render/mesh_renderer/build/test_device', '1']' returned non-zero exit status 1.\n",
      "INFO:igibson.render.mesh_renderer.get_available_devices:Device 1 is not available for rendering\n",
      "INFO:igibson.scenes.scene_base:Loading scene...\n",
      "INFO:igibson.scenes.scene_base:Scene loaded!\n",
      "WARNING:igibson.simulator:DEPRECATED: simulator.import_robot(...) has been deprecated in favor of import_object and will be removed in a future release. Please use simulator.import_object(...) for equivalent functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "left_hand_shoulderb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "right_hand_shoulderb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "neckb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "eyes"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "s = Simulator(\n",
    "    mode=\"headless\",\n",
    "    image_width=512,\n",
    "    image_height=512,\n",
    "    device_idx=0,\n",
    "    use_pb_gui=False,\n",
    ")\n",
    "scene = InteractiveIndoorScene(\n",
    "    \"Rs_int\", load_object_categories=[\"walls\", \"floors\", \"bottom_cabinet\", \"door\", \"sink\", \"coffee_table\", \"fridge\"]\n",
    ")\n",
    "s.import_scene(scene)\n",
    "\n",
    "# Load the robot and place it in the scene.\n",
    "config = parse_config(os.path.join(igibson.configs_path, \"behavior_robot_mp_behavior_task.yaml\"))\n",
    "config[\"robot\"][\"show_visual_head\"] = True\n",
    "robot = BehaviorRobot(**config[\"robot\"])\n",
    "s.import_robot(robot)\n",
    "\n",
    "robot.set_position_orientation([0, 0, 1], p.getQuaternionFromEuler([0, 0, -np.pi/4])) # positive offset on the third dim -> turn left, negavite -> turn right\n",
    "robot.apply_action(\n",
    "    np.zeros(\n",
    "        robot.action_dim,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run some steps to let physics settle.\n",
    "for _ in range(300):\n",
    "    s.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867b3759-9f3d-4910-af27-b7444c51bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyquaternion  \n",
    "\n",
    "def render_robot_pov(robot, step):\n",
    "    robot_pos, robot_orientation = robot.get_position_orientation()\n",
    "    \n",
    "    # Convert quaternion to rotation matrix - takes w,x,y,z in input, but robot orientation is given as x,y,z,w !!!\n",
    "    q = pyquaternion.Quaternion(x=robot_orientation[0], \n",
    "                                y=robot_orientation[1], \n",
    "                                z=robot_orientation[2], \n",
    "                                w=robot_orientation[3])\n",
    "    \n",
    "    forward_downward_direction = q.rotate(np.array([1, 0, -0.25]))  # Default forward vector (x-axis)\n",
    "    up_direction = q.rotate(np.array([0, 0, 1]))  # Default up vector (z-axis)\n",
    "    \n",
    "    # Set the camera at the robot's head level (optional: raise it slightly)\n",
    "    camera_pose = robot_pos + q.rotate(np.array([0.1, 0.1, 1])) # Slightly above the robot's center\n",
    "    \n",
    "    # Set the camera in the renderer\n",
    "    s.renderer.set_camera(camera_pose, camera_pose + forward_downward_direction, up_direction)\n",
    "    frame = s.renderer.render(modes=(\"rgb\"))[0]\n",
    "    rgb_image = (frame[..., :3] * 255).astype(np.uint8) \n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(\"./images/rendering_attempts\", exist_ok=True)\n",
    "    \n",
    "    # Save using PIL\n",
    "    image = Image.fromarray(rgb_image)\n",
    "    #image.show()\n",
    "    image.save(f\"./images/rendering_attempts/img_1st_person_{step}.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c931ee6-00c8-42a2-8cd3-1fe03c452272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:igibson.action_primitives.starter_semantic_action_primitives:The StarterSemanticActionPrimitive is a work-in-progress and is only provided as an example. It currently only works with BehaviorRobot with its JointControllers set to absolute mode. See provided behavior_robot_mp_behavior_task.yaml config file for an example. See examples/action_primitives for runnable examples.\n"
     ]
    }
   ],
   "source": [
    "controller = StarterSemanticActionPrimitives(None, scene, robot)\n",
    "obj = s.scene.objects_by_category[\"coffee_table\"][0]\n",
    "ctrl_gen = controller._navigate_to_obj(obj)\n",
    "for i, action in enumerate(ctrl_gen):\n",
    "    robot.apply_action(action)\n",
    "    s.step()\n",
    "    if i % 5 == 0:\n",
    "        render_robot_pov(robot, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ce82c-fba6-4dcb-ba3b-938ee7a311cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
