{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55fb69c6-de32-4eb2-9c94-d0706989486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "import yaml\n",
    "\n",
    "import igibson\n",
    "from igibson.action_primitives.action_primitive_set_base import ActionPrimitiveError\n",
    "from igibson.action_primitives.starter_semantic_action_primitives import StarterSemanticActionPrimitives\n",
    "from igibson.objects.articulated_object import URDFObject\n",
    "from igibson.robots.behavior_robot import BehaviorRobot\n",
    "from igibson.robots.fetch import Fetch\n",
    "from igibson.scenes.igibson_indoor_scene import InteractiveIndoorScene\n",
    "from igibson.simulator import Simulator\n",
    "from igibson.utils.assets_utils import get_ig_avg_category_specs, get_ig_model_path\n",
    "from igibson.utils.utils import parse_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "823588f1-0bbc-4cda-bbca-664e93cb5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_controller(ctrl_gen, robot, s):\n",
    "    for action in ctrl_gen:\n",
    "        robot.apply_action(action)\n",
    "        s.step()\n",
    "\n",
    "\n",
    "def go_to_sink_and_toggle(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Go to the sink object in the scene and toggle it on.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            sink = s.scene.objects_by_category[\"sink\"][1]\n",
    "            print(\"Trying to NAVIGATE_TO sink.\")\n",
    "            execute_controller(controller._navigate_to_obj(sink), robot, s)\n",
    "            print(\"NAVIGATE_TO sink succeeded!\")\n",
    "            print(\"Trying to TOGGLE_ON the sink.\")\n",
    "            execute_controller(controller.toggle_on(sink), robot, s)\n",
    "            print(\"TOGGLE_ON the sink succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to navigate and toggle on the sink failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def grasp_tray(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Grasp the tray that's on the floor of the room.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            print(\"Trying to GRASP tray.\")\n",
    "            tray = s.scene.objects_by_category[\"tray\"][0]\n",
    "            execute_controller(controller.grasp(tray), robot, s)\n",
    "            print(\"GRASP the tray succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to grasp the tray failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def put_on_table(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Place the currently-held object on top of the coffee table.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            print(\"Trying to PLACE_ON_TOP the held object on coffee table.\")\n",
    "            table = s.scene.objects_by_category[\"coffee_table\"][0]\n",
    "            execute_controller(controller.place_on_top(table), robot, s)\n",
    "            print(\"PLACE_ON_TOP succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to place the held object failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def open_and_close_fridge(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Demonstrate opening and closing the fridge.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            fridge = s.scene.objects_by_category[\"fridge\"][0]\n",
    "            print(\"Trying to OPEN the fridge.\")\n",
    "            execute_controller(controller.open(fridge), robot, s)\n",
    "            print(\"OPEN the fridge succeeded!\")\n",
    "            print(\"Trying to CLOSE the fridge.\")\n",
    "            execute_controller(controller.close(fridge), robot, s)\n",
    "            print(\"CLOSE the fridge succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to open and close the fridge failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def open_and_close_door(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Demonstrate opening and closing the bathroom door.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            door = (set(s.scene.objects_by_category[\"door\"]) & set(s.scene.objects_by_room[\"bathroom_0\"])).pop()\n",
    "            print(\"Trying to OPEN the door.\")\n",
    "            execute_controller(controller.open(door), robot, s)\n",
    "            print(\"Trying to CLOSE the door.\")\n",
    "            execute_controller(controller.close(door), robot, s)\n",
    "            print(\"CLOSE the door succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to open and close the door failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def open_and_close_cabinet(s, robot, controller: StarterSemanticActionPrimitives):\n",
    "    \"\"\"Demonstrate opening and closing a drawer unit.\"\"\"\n",
    "    for i in range(20):\n",
    "        try:\n",
    "            cabinet = s.scene.objects_by_category[\"bottom_cabinet\"][2]\n",
    "            print(\"Trying to OPEN the cabinet.\")\n",
    "            execute_controller(controller.open(cabinet), robot, s)\n",
    "            print(\"Trying to CLOSE the cabinet.\")\n",
    "            execute_controller(controller.close(cabinet), robot, s)\n",
    "            print(\"CLOSE the cabinet succeeded!\")\n",
    "        except ActionPrimitiveError:\n",
    "            print(\"Attempt {} to open and close the cabinet failed. Retry until 20.\".format(i + 1))\n",
    "            continue\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c7cd70b-0f63-4379-b2b2-45451c957b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:igibson.render.mesh_renderer.get_available_devices:Device 0 is available for rendering\n",
      "INFO:igibson.render.mesh_renderer.get_available_devices:Command '['/home/nicola/python_projects/iGibson/igibson/render/mesh_renderer/build/test_device', '1']' returned non-zero exit status 1.\n",
      "INFO:igibson.render.mesh_renderer.get_available_devices:Device 1 is not available for rendering\n",
      "INFO:igibson.scenes.scene_base:Loading scene...\n",
      "INFO:igibson.scenes.scene_base:Scene loaded!\n",
      "WARNING:igibson.simulator:DEPRECATED: simulator.import_robot(...) has been deprecated in favor of import_object and will be removed in a future release. Please use simulator.import_object(...) for equivalent functionality.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "s = Simulator(\n",
    "    mode=\"headless\",\n",
    "    image_width=512,\n",
    "    image_height=512,\n",
    "    device_idx=0,\n",
    "    use_pb_gui=False,\n",
    ")\n",
    "scene = InteractiveIndoorScene(\n",
    "    \"Rs_int\", load_object_categories=[\"walls\", \"floors\", \"bottom_cabinet\", \"door\", \"sink\", \"coffee_table\", \"fridge\"]\n",
    ")\n",
    "s.import_scene(scene)\n",
    "\n",
    "# Create a custom tray object for the grasping test.\n",
    "model_path = get_ig_model_path(\"tray\", \"tray_000\")\n",
    "model_filename = os.path.join(model_path, \"tray_000.urdf\")\n",
    "avg_category_spec = get_ig_avg_category_specs()\n",
    "tray = URDFObject(\n",
    "    filename=model_filename,\n",
    "    category=\"tray\",\n",
    "    name=\"tray\",\n",
    "    avg_obj_dims=avg_category_spec.get(\"tray\"),\n",
    "    fit_avg_dim_volume=True,\n",
    "    model_path=model_path,\n",
    ")\n",
    "s.import_object(tray)\n",
    "tray.set_position_orientation([0, 1, 0.3], p.getQuaternionFromEuler([0, np.pi / 2, 0]))\n",
    "\n",
    "# Load the robot and place it in the scene.\n",
    "#config = parse_config(os.path.join(igibson.configs_path, \"behavior_robot_mp_behavior_task.yaml\"))\n",
    "config = parse_config(os.path.join(igibson.configs_path, \"fetch_motion_planning.yaml\"))\n",
    "\n",
    "#config[\"robot\"][\"show_visual_head\"] = True\n",
    "robot = Fetch(**config[\"robot\"])\n",
    "s.import_robot(robot)\n",
    "robot.set_position_orientation([0, 0, 1], p.getQuaternionFromEuler([0, 0, -np.pi/4])) # positive offset on the third dim -> turn left, negavite -> turn right\n",
    "robot.apply_action(\n",
    "    np.zeros(\n",
    "        robot.action_dim,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run some steps to let physics settle.\n",
    "for _ in range(300):\n",
    "    s.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "705a3219-f390-4ebc-9a9a-510dfbf1ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_pos, robot_orientation = robot.get_position_orientation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "05928531-c146-423b-835c-c6a23743a5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00453328,  0.01126892, -0.38878708,  0.92124756])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0320bc62-6a82-4721-8d25-c5df74a6ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle: 0 - View direction: [ 0.69743523 -0.71623613 -0.0242879 ]\n",
      "Image saved at ./images/img_0_deg.jpg\n",
      "Angle: 45 - View direction: [ 0.9997611  -0.01314371 -0.01746396]\n",
      "Image saved at ./images/img_45_deg.jpg\n",
      "Angle: 90 - View direction: [ 7.1644047e-01  6.9764811e-01 -4.0987053e-04]\n",
      "Image saved at ./images/img_90_deg.jpg\n",
      "Angle: 135 - View direction: [0.01343873 0.99976713 0.01688432]\n",
      "Image saved at ./images/img_135_deg.jpg\n",
      "Angle: 180 - View direction: [-0.69743523  0.71623613  0.0242879 ]\n",
      "Image saved at ./images/img_180_deg.jpg\n",
      "Angle: 225 - View direction: [-0.9997611   0.01314371  0.01746396]\n",
      "Image saved at ./images/img_225_deg.jpg\n",
      "Angle: 270 - View direction: [-7.1644047e-01 -6.9764811e-01  4.0987053e-04]\n",
      "Image saved at ./images/img_270_deg.jpg\n",
      "Angle: 315 - View direction: [-0.01343873 -0.99976713 -0.01688432]\n",
      "Image saved at ./images/img_315_deg.jpg\n",
      "Angle: 360 - View direction: [ 0.69743523 -0.71623613 -0.0242879 ]\n",
      "Image saved at ./images/img_360_deg.jpg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_view_dir(angle_deg):\n",
    "    \"\"\"\n",
    "    Given angle in degrees, return the view direction in the xy plane corresponding to the angle. \n",
    "    Consider that: \n",
    "    angle_deg=0 -> np.array([1,0,0]) \n",
    "    angle_deg=90 -> np.array([0,1,0])\n",
    "    \"\"\"\n",
    "    import math\n",
    "    angle_rad = angle_deg * math.pi / 180 \n",
    "    x = math.cos(angle_rad)\n",
    "    y = math.sin(angle_rad)\n",
    "    return np.array([x,y,0])\n",
    "\n",
    "angles = [0, 45, 90, 135, 180, 225, 270, 315, 360]\n",
    "for angle in angles:\n",
    "    # from examples/renderer/mesh_renderer_gpu_example\n",
    "    camera_pose = robot_pos + q.rotate(np.array([0.1, 0.1, 1])) #+ np.array([0.5, 0.5, 0.5])\n",
    "    view_direction = q.rotate(get_view_dir(angle))\n",
    "    print(f\"Angle: {angle} - View direction: {view_direction}\")\n",
    "    \n",
    "    s.renderer.set_camera(camera_pose, camera_pose + view_direction, q.rotate([0, 0, 1]))\n",
    "    s.renderer.set_fov(120)\n",
    "    \n",
    "    frame = s.renderer.render(modes=(\"rgb\"))[0]\n",
    "    rgb_image = (frame[..., :3] * 255).astype(np.uint8) \n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(\"./images/rendering_attempts\", exist_ok=True)\n",
    "    \n",
    "    # Save using PIL\n",
    "    image = Image.fromarray(rgb_image)\n",
    "    #image.show()\n",
    "    image.save(f\"./images/rendering_attempts/img_{angle}_deg.jpg\", \"JPEG\")\n",
    "    \n",
    "    print(\"Image saved at \"+f\"./images/rendering_attempts/img_{angle}_deg.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dda341de-1558-45e7-b5d6-8fa8e43d8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we get the robot camera PoV?\n",
    "import pyquaternion  \n",
    "\n",
    "robot_pos, robot_orientation = robot.get_position_orientation()\n",
    "\n",
    "# Convert quaternion to rotation matrix - takes w,x,y,z in input, but robot orientation is given as x,y,z,w !!!\n",
    "q = pyquaternion.Quaternion(x=robot_orientation[0], \n",
    "                            y=robot_orientation[1], \n",
    "                            z=robot_orientation[2], \n",
    "                            w=robot_orientation[3])\n",
    "\n",
    "forward_downward_direction = q.rotate(np.array([1, 0, -0.25]))  # Default forward vector (x-axis)\n",
    "up_direction = q.rotate(np.array([0, 0, 1]))  # Default up vector (z-axis)\n",
    "\n",
    "# Set the camera at the robot's head level (optional: raise it slightly)\n",
    "camera_pose = robot_pos + q.rotate(np.array([0.1, 0.1, 1])) # Slightly above the robot's center\n",
    "\n",
    "# Set the camera in the renderer\n",
    "s.renderer.set_camera(camera_pose, camera_pose + forward_downward_direction, up_direction)\n",
    "frame = s.renderer.render(modes=(\"rgb\"))[0]\n",
    "rgb_image = (frame[..., :3] * 255).astype(np.uint8) \n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"./images/rendering_attempts\", exist_ok=True)\n",
    "\n",
    "# Save using PIL\n",
    "image = Image.fromarray(rgb_image)\n",
    "#image.show()\n",
    "image.save(f\"./images/rendering_attempts/img_1st_person.jpg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6164c357-e3f3-425d-883c-e68a2ab06cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
